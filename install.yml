---
 
- hosts: localhost

  vars_files: 
     - clouds.yaml

  tasks:

  - name: generate slurm user ssh key
    shell: ssh-keygen -b 2048 -t rsa -f /etc/slurm/.ssh/id_rsa -q -N ""
    args:
      creates: /etc/slurm/.ssh/id_rsa
    become: yes 
    become_user: slurm

  - name: add slurm user key to openstack
    os_keypair:
      cloud: "{{ cloud_name }}"
      state: present
      name: "{{ JS_ssh_keyname }}"
      public_key_file: /etc/slurm/.ssh/id_rsa.pub

  - name: add proper entry for compute nodes in /etc/ansible/ssh.cfg
    blockinfile:
      path: /etc/ansible/ssh.cfg
      insertafter: EOF
      marker: "#{mark} MANAGED COMPUTE INSTANCE SSH CONFIG" 
      create: yes
      state: present
      block: |
       Host 149.165.*
         User centos
         StrictHostKeyChecking no
         BatchMode yes
         UserKnownHostsFile=/dev/null
         IdentityFile /etc/slurm/.ssh/id_rsa

  - name: allow slurm to write to /home/centos/.ssh/authorized_keys
    shell: setfacl -m u:slurm:rw /home/centos && setfactl -m u:slurm:rwx /home/centos/.ssh/authorized_keys

  - name: allow slurm to write to etc/hosts
    shell: setfacl -m u:slurm:rw /etc/hosts && setfactl -m u:slurm:rwx /etc
#    acl:
#      path: /etc/hosts
#      permissions: rw
#      etype: user
#      entity: slurm

  - name: create a private network
    os_network:
      cloud: "{{ cloud_name }}"
      external: no
      name: "{{ network_name }}"

#  - name: Display all variables/facts known for a host
#    debug:
#      var: hostvars[inventory_hostname]
#      name: "{{ cloud.tacc.auth.username }}-{{ cloud.tacc.auth.project_name }}-private"

  - name: create security group for internal ports
    os_security_group:
      cloud: "{{ cloud_name }}"
      state: present
      name: "{{ sec_group_internal }}"
      description: security group for internal access

  - name: allow icmp internally
    os_security_group_rule:
      cloud: "{{ cloud_name }}"
      security_group: "{{ sec_group_internal }}"
      protocol: icmp
      remote_ip_prefix: "{{ network_cidr }}"

  - name: allow all tcp internally
    os_security_group_rule:
      cloud: "{{ cloud_name }}"
      security_group: "{{ sec_group_internal }}"
      protocol: tcp 
      port_range_min: 1
      port_range_max: 65535
      remote_ip_prefix: "{{ network_cidr }}"

  - name: allow all udp internally
    os_security_group_rule:
      cloud: "{{ cloud_name }}"
      security_group: "{{ sec_group_internal }}"
      protocol: udp 
      port_range_min: 1
      port_range_max: 65535
      remote_ip_prefix: "{{ network_cidr }}"

  - name: create public-facing security group
    os_security_group:
     cloud: "{{ cloud_name }}"
     state: present
     name: "{{ sec_group_global }}"
     description: security group for global access

  - name: allow icmp globally
    os_security_group_rule:
      cloud: "{{ cloud_name }}"
      security_group: "{{ sec_group_global }}"
      protocol: icmp
      remote_ip_prefix: "0.0.0.0/0"

  - name: allow ssh globally
    os_security_group_rule:
      cloud: "{{ cloud_name }}"
      security_group: "{{ sec_group_global }}"
      protocol: tcp
      port_range_min: 22
      port_range_max: 22
      remote_ip_prefix: "0.0.0.0/0"

  - name: allow https globally
    os_security_group_rule:
      cloud: "{{ cloud_name }}"
      security_group: "{{ sec_group_global }}"
      protocol: tcp
      port_range_min: 443
      port_range_max: 443
      remote_ip_prefix: "0.0.0.0/0"

  - name: create a subnet within private network
    os_subnet:
      state: present
      network_name: "{{ network_name }}"
      name: "{{ subnet_name }}"
      cidr: "{{ network_cidr }}"
      cloud: "{{ cloud_name }}"

  - name: create a router on the private network
    os_router:
      cloud: "{{ cloud_name }}"
      state: present
      name: "{{ router_name }}"
      network: public
      interfaces:
        - "{{ subnet_name }}"

  - name: update slurm.conf for cloud configuration
    blockinfile:
      path: /etc/slurm/slurm.conf
      insertbefore: "#COMPUTE NODES"
      marker: "#{mark} MANAGED CLOUD CONFIGURATION"
      state: present
      block: |
        #CLOUD CONFIGURATION
        PrivateData=cloud
        ResumeProgram=/usr/local/sbin/slurm_resume_ansible.sh
        SuspendProgram=/usr/local/sbin/slurm_suspend_ansible.sh
        ResumeRate=0 
        ResumeTimeout=900 
        SuspendRate=0 
        SuspendTime=60 
        SuspendTimeout=30

  - name: copy files into place for slurm suspend and resume
    copy:
      dest: "{{ item.path }}"
      src: "{{ item.name }}"
      owner: "slurm"
      group: "slurm"
      mode: "{{ item.mode }}"
    loop:
      - { name: slurm_resume_ansible.sh, path: /usr/local/sbin/, mode: '0744' }
      - { name: slurm_prolog.sh, path: /usr/local/sbin/, mode: '0744' }
      - { name: slurm_suspend_ansible.sh, path: /usr/local/sbin/, mode: '0744' }
      - { name: group_vars, path: /etc/slurm/, mode: '0744' }
      - { name: clouds.yaml, path: /etc/slurm/, mode: '0600' }
      - { name: computes.yml, path: /etc/slurm/, mode: '0644' }
      - { name: create_nodes.yml, path: /etc/slurm/, mode: '0644' }
      - { name: destroy_nodes.yml, path: /etc/slurm/, mode: '0644' }
      - { name: config_computes.yml, path: /etc/slurm/, mode: '0644' }

  - name: insert cloud nodes into slurm.conf
    blockinfile:
      path: /etc/slurm/slurm.conf
      insertafter: "#COMPUTE NODES"
      marker: "#{mark} MANAGED COMPUTE NODE CONFIGURATION"
      state: present
      block: |
        NodeName={{ compute_glob_slurm }} State=CLOUD

  - name: insert remote cloud partition into slurm.conf
    blockinfile:
      path: /etc/slurm/slurm.conf
      insertafter: "#PARTITIONS"
      marker: "#{mark} MANAGED PARTITION CONFIGURATION"
      state: present
      block: |
        PartitionName=remote-cloud  Nodes={{ compute_glob_slurm }} Default=YES MaxTime=INFINITE State=UP 
  - name: restart slurmctld
    service:
      name: slurmctld
      state: restarted
      enabled: yes
