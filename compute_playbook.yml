---

- hosts: compute-*
  tasks:

  - name: Get the headnode private IP
    local_action:
      module: shell ip addr | grep -Eo '10.0.0.[0-9]*' | head -1
    register: headnode_private_ip
    become: False # for running as slurm, since no sudo on localhost

  - name: Get the slurmctld uid
    local_action:
      module: shell getent passwd slurm | awk -F':' '{print $3}'
    register: headnode_slurm_uid
    become: False # for running as slurm, since no sudo on localhost

  - name: Add OpenHPC 1.3.5 repo
    yum_repository:
      name: OpenHPC
      description: OpenHPC 1.3.5 repo
      file: OpenHPC
      baseurl: http://build.openhpc.community/OpenHPC:/1.3:/Update5/CentOS_7/
      gpgkey: http://build.openhpc.community/OpenHPC:/1.3:/Update5/CentOS_7/repodata/repomd.xml.key
      gpgcheck: yes

  - name: install basic packages
    yum: name={{ item }} state=present
    with_items:
      - "https://github.com/openhpc/ohpc/releases/download/v1.3.GA/ohpc-release-1.3-1.el7.x86_64.rpm"
      - "openmpi"       #torque
      - "libselinux-python"
      - "telnet"
      - "bind-utils"
      - "vim"
      - "ohpc-slurm-client"
 #    - "quantum-espresso-openmpi"
 #    - "quantum-espresso"
 #     - "rsync"
 #     - "epel-release"
 #     - "openmpi-devel"       #torque
 #     - "gcc"           
 #     - "gcc-c++"       
 #     - "gcc-gfortran"  
 #     - "openssl-devel" 
 #     - "libxml2-devel" 
 #     - "boost-devel"   
 #     - "net-tools"
 #     - "strace"
 #     - "wget"  # needed for building QE
 #     - "readline-devel"  #req for slurm
 #     - "pam-devel"       # req for slurm
 #     - "perl-ExtUtils-MakeMaker" # req for slurm
 #     - "fftw" # req for QE... need a better way to specify these!!!
 #
# - name: set up /etc/hosts
#   template: src=hosts.j2 dest=/etc/hosts

#  - name: install stuff from epel and openHPC
#    yum: name={{ item }} state=latest
#    with_items:

  - name: fix slurm user uid
    user:
      name: slurm
      uid: "{{ headnode_slurm_uid.stdout}}"
      shell: "/sbin/nologin"
      home: "/etc/slurm"

  - name: change ownership of slurm files
    file:
      path: "{{ item }}"
      owner: slurm
      group: slurm
    with_items:
      - "/var/log/slurm_jobacct.log"
      - "/var/spool/slurm"
      - "/var/spool/slurm/ctld"

 # - name: install pexpect from pip
 #   pip: name=pexpect version=3.3
 #   when: submit_host == "yes"
 
 # - name: turn off requiretty for sudo
 #   lineinfile:
 #     dest: /etc/sudoers
 #     regexp: "Defaults    requiretty"
 #     line:  "Defaults    !requiretty"
 #     state: present
 #
 # - name: fix sudo path (for qterm, etc)
 #   lineinfile:
 #     dest: /etc/sudoers
 #     regexp: "Defaults    secure_path = /sbin:/bin:/usr/sbin:/usr/bin"
 #     line: "Defaults    secure_path = /sbin:/bin:/usr/sbin:/usr/bin:/usr/local/bin"
 #     state: present
 
 # - name: export /home to compute nodes
 #   lineinfile:
 #     dest: /etc/exports
 #     line:  "/home 10.0.0.0/24(rw,no_root_squash)"
 #     state: present
 #   tags:
 #     - export_home
 #   when: submit_host == "yes"
 
 # - name: allow all to write /export
 #   file: 
 #     path: /export/
 #     state: directory
 #     mode: 0777
 #
 # - name: export /export to compute nodes
 #   lineinfile:
 #     dest: /etc/exports
 #     line:  "/export 10.0.0.0/24(rw,no_root_squash)"
 #     state: present
 #   tags:
 #     - export_N
 #   when: submit_host == "yes"
 
  - name: allow use_nfs_home_dirs
    seboolean: name=use_nfs_home_dirs state=yes persistent=yes
 #
 # - name: restart nfs
 #   service: name=nfs state=restarted
 #   when: (submit_host == "yes" and cleanup == "no")
  
  
  - name: import /home on compute nodes
    lineinfile:
      dest: /etc/fstab
      line:  "{{ headnode_private_ip.stdout }}:/home  /home  nfs  defaults,nfsvers=4.0 0 0"
      state: present
    tags:
      - export_home

  - name: ensure /export exists
    file: path=/export state=directory mode=777
 
  - name: import /export on compute nodes
    lineinfile:
      dest: /etc/fstab
      line:  "{{ headnode_private_ip.stdout }}:/export  /export  nfs  defaults,nfsvers=4.0 0 0"
      state: present
    tags:
      - export_home
 
 # - name: import firewalld public zone
 #   template: src=public.xml dest=/etc/firewalld/zones/public.xml
 
 # - name: restart/enable firewalld
 #   service: name=firewalld state=restarted enabled=yes
  
 #This might not matter for JS - compute nodes have NAT...?
 # - name: make sure ntp is installed
 #   yum: name=ntp state=present
 #
 # - name: ntp server template
 #   template: src={{ ntp_type }}_ntp.conf.j2 dest=/etc/ntp.conf
 #
 # - name: start and enable ntpd
 #   service: name=ntpd state=restarted enabled=yes
 
 # - name: install the XNIT repository
 #   yum_repository:
 #     name: xnit
 #     description: XSEDE National Integration Toolkit
 #     baseurl: http://cb-repo.iu.xsede.org/xsederepo/centos7
 #     enabled: yes
 #     gpgcheck: no
 
 #   - name: start slurmctld 
 #     service: name=slurmctld state=restarted enabled=yes
 #     when: submit_host == "yes"
 #
  - name: add local users to compute node
    script: /tmp/add_users.sh
    ignore_errors: True

# - name: copy add_users script
#   synchronize:
#     mode: push
#     src: /tmp/add_users.sh
#     dest: /tmp/add_users.sh
#     set_remote_user: no
#     use_ssh_args: yes
#
# - name: run add_users.sh
#   command: /tmp/add_users.sh
   
  - name: copy munge key from headnode
    synchronize:
      mode: push
      src: /etc/slurm/.munge.key
      dest: /etc/munge/munge.key
      set_remote_user: no
      use_ssh_args: yes

  - name: fix perms on munge key
    file: 
      path: /etc/munge/munge.key
      owner: munge
      group: munge
      mode: 0600
 
  - name: copy slurm.conf from headnode
    synchronize:
      mode: push
      src: /etc/slurm/slurm.conf
      dest: /etc/slurm/slurm.conf
      set_remote_user: no
      use_ssh_args: yes
 
  - name: copy slurm_prolog.sh from headnode
    synchronize:
      mode: push
      src: /usr/local/sbin/slurm_prolog.sh
      dest: /usr/local/sbin/slurm_prolog.sh
      set_remote_user: no
      use_ssh_args: yes
 
  - name: enable and start munge
    service: name=munge.service enabled=yes state=started
 
  - name: start slurmd
    service: name=slurmd state=restarted enabled=yes

  - name: mount -a on compute nodes
    command: "mount -a"
    tags:
      - export_home
 
#  - vars:
#      headnode_private_ip: 10.0.0.6
